[{"body":"CreateMatchPhrasesAsync and CreateMatchPhrases The intent of the ISearchResults\u003cT\u003e.CreateMatchPhrasesAsync methods is to allow you to provide a mechanism by which LIFTI can retrieve the original source text, from objects or loosely indexed text, and automatically extract phrases for the matched token locations. Where a multiple tokens are matched in a sequence, they will be combined into a single phrase.\nFor the CreateMatchPhrasesAsync\u003cTObject\u003e overloads that create the matched phrases from an indexed object of type TObject, you can either fetch the objects one at a time, or be provided with a list of keys and fetch all the relevant objects in bulk. The latter is more efficient if you are having to go to an external source for the data, e.g. using a database query.\nExample This example demonstrates searching against an index of Book objects:\npublic class Book { public int BookId { get; set; } public string Title { get; set; } public string[] Authors { get; set; } public string Synopsis { get; set; } } var bookIndex = new FullTextIndexBuilder\u003cint\u003e() // Books are indexed by their BookId property, which is an int. .WithObjectTokenization\u003cBook\u003e( options =\u003e options .WithKey(b =\u003e b.BookId) .WithField(\"Title\", b =\u003e b.Title, tokenOptions =\u003e tokenOptions.WithStemming()) .WithField(\"Authors\", b =\u003e b.Authors) .WithField(\"Synopsis\", b =\u003e b.Synopsis, tokenOptions =\u003e tokenOptions.WithStemming())) .Build(); var results = bookIndex.Search(\"first | novel\"); And then printing the matched phrases from each of the fields to the console window:\nforeach (var result in await results.CreateMatchPhrasesAsync(i =\u003e books.First(x =\u003e x.BookId == i))) { Console.WriteLine($\"{result.SearchResult.Key} ({result.SearchResult.Score})\"); foreach (var fieldPhrase in result.FieldPhrases) { Console.Write($\" {fieldPhrase.FoundIn}: \"); Console.WriteLine(string.Join(\", \", fieldPhrase.Phrases.Select(x =\u003e $\"\\\"{x}\\\"\"))); } } ","categories":"","description":"`ISearchResults\u003cT\u003e` provides methods that allow you to combine the original source text with the search results and extract the matched phrases.","excerpt":"`ISearchResults\u003cT\u003e` provides methods that allow you to combine the …","ref":"/lifti/docs/searching/search-results/extracting-matched-phrases/","tags":"","title":"Extracting matched phrases"},{"body":"Perhaps the simplest way to work with LIFTI is to index text against a key that means something in some other system.\nIn this example, we’re just indexing three pieces of text against 3 integer keys:\n// Create a full text index with default settings and integer keys var index = new FullTextIndexBuilder\u003cint\u003e().Build(); // Index keys with their associated text await index.AddAsync(1, \"This is some text associated with A: fizz\"); await index.AddAsync(2, \"Some buzz text for B\"); await index.AddAsync(3, \"Text associated with C is both fizz and buzz\"); You can search in this index using:\n// Search for documents containing both Fizz *and* Buzz var results = index.Search(\"Fizz Buzz\").ToList(); // Output: Documents with both Fizz and Buzz: 1 Console.WriteLine($\"Documents with both Fizz and Buzz: {results.Count}\"); // Search for documents containing both Fizz *or* Buzz results = index.Search(\"Fizz | Buzz\").ToList(); // Outputs: Documents with Fizz or Buzz: 3 Console.WriteLine($\"Documents with Fizz or Buzz: {results.Count}\"); Each set of results returns the keys that the text was indexed against. For example, the first set of results will return a key of 3, as that is the only key that was indexed with both “fizz” and “buzz”.\n","categories":"","description":"The simplest possible way to create a LIFTI index, index some text in it and retrieve search results.\n","excerpt":"The simplest possible way to create a LIFTI index, index some text in …","ref":"/lifti/docs/getting-started/","tags":"","title":"Getting Started"},{"body":"Let’s say you need to index more than one data point against an index:\nUserId of type Int32 CompanyId of type Int16 You would have a class or struct something like this:\npublic struct CompositeKey { public CompositeKey(int userId, short companyId) { this.UserId = userId; this.CompanyId = companyId; } public int UserId { get; } public short CompanyId { get; } } Building and populating an index with this type as a key is as easy as ever:\n// Create a full text index with a custom key type var index = new FullTextIndexBuilder\u003cCompositeKey\u003e().Build(); // Index some sample data await index.AddAsync(new CompositeKey(1, 9), \"This is some text associated with A: fizz\"); await index.AddAsync(new CompositeKey(2, 9), \"Some buzz text for B\"); await index.AddAsync(new CompositeKey(3, 11), \"Text associated with C is both fizz and buzz\"); CompositeKey could also be the key of an object that you want to index. You’d just need to use the configure the FullTextIndexBuilder with the appropriate WithKey call when setting up the object tokenization options.\nThe only additional work comes when constructing the BinarySerializer - here you need to pass a custom IKeySerializer implementation so that the serializer knows how to read and write the data in your custom key:\n// This would error with: No standard key serializer exists for type CompositeKey - // please provide a custom implementation of IKeySerializer\u003c\u003e when serializing/deserializing. // var serializer = new BinarySerializer\u003cint\u003e(); var serializer = new BinarySerializer\u003cCompositeKey\u003e(new CompositeKeySerializer()); using var stream = new MemoryStream(); Where your custom serializer is defined as:\npublic class CompositeKeySerializer : IKeySerializer\u003cCompositeKey\u003e { public void Write(BinaryWriter writer, CompositeKey key) { writer.Write(key.UserId); // Int32 writer.Write(key.CompanyId); // Int16 } public CompositeKey Read(BinaryReader reader) { // The serialization framework will make sure this method is only // ever called when a key is ready to be read. // Ensure the data is read is read out in exactly the same order and with the same // data types it was written. var userId = reader.ReadInt32(); var companyId = reader.ReadInt16(); return new CompositeKey(userId, companyId); } } And then serialization and deserialization will just work as normal:\n// Serialize the index await serializer.SerializeAsync(index, stream, disposeStream: false); // Deserialize the index into a new instance stream.Position = 0; var newIndex = new FullTextIndexBuilder\u003cCompositeKey\u003e().Build(); await serializer.DeserializeAsync(newIndex, stream, disposeStream: false); // Prove that the new index has the same contents and the keys have round-tripped // Emits: only (3, 11) contains Fizz \u0026 Buzz var match = newIndex.Search(\"fizz \u0026 buzz\").Single(); Console.WriteLine($\"Only ({match.Key.UserId}, {match.Key.CompanyId}) contains Fizz \u0026 Buzz\"); ","categories":"","description":"The BinarySerializer can automatically handle keys of type `String`, `Int32`, `UInt32` and `Guid`. If you need a different type of key in your index, you will need to create a custom implementation of `IKeySerializer`.\n","excerpt":"The BinarySerializer can automatically handle keys of type `String`, …","ref":"/lifti/docs/serialization/key-serialization/","tags":"","title":"Key Serialization"},{"body":" Don’t want to use advanced queries? You’ll want to configure the simple query parser.\nQuick examples Example Meaning West West must appear in the text exactly. West|Wing^2 West or Wing must appear in the text exactly, where matches on Wing will have a score boost of 2. ?Wst Words that fuzzy match with wst must appear in the text. ?3,2?Wst Words that fuzzy match with wst must appear in the text, with a specified max edit distance and max sequential edits. title=West A field restricted search. West must appear in the title field of an indexed object. doc* Words that starts with document must appear in the text. See wildcard matching %%ing Words that starts with any two letters and end with ing, e.g. doing. See wildcard matching west \u0026 wing The words west and wing must appear in the text. west wing The words west and wing must appear in the text - the default operator is \u0026 if none is specified between search words. west | wing The words west or wing must appear in the text. west ~ wing west and wing must appear near to each other (within 5 words - the default) in the text. west ~3 wing west and wing must appear near to each other (within 3 words) in the text. west ~\u003e wing west must be followed by wing closely (within 5 words - the default) in the text. west ~3\u003e wing west must be followed by wing closely (within 3 words) in the text. west \u003e wing west must precede wing anywhere in the text “the west wing” The words the west wing must appear in sequence in the indexed text. “notr* dam*” You can use wildcards and fuzzy matching in a sequential text query. In this case, a word starting with notr must be immediately followed by a word starting with dam, e.g. Notre Dame. Search terms can be combined and placed in parenthesis:\nExample Meaning “west wing” ~ “oval office” West wing must appear near Oval Office (west | east) \u0026 wing west wing or east wing must appear in the document. Query Operators Exact word matches Any text in a query will be tokenized using to the provided tokenizer, enforcing the same word stemming, case/accent sensitivity rules as used in the index.\nFuzzy match (?) By prefixing a search term with ? a fuzzy matching algorithm will be used to match the search term against the index. You can optionally specify the maximum edit distance and maximum number of sequential edits for a specific search term using the formats:\n?{max edits},{max sequential edits}?term\nFor example ?2,1?food will search for “food” with a maximum number of edits of 2, and maximum sequential edits of 1.\nYou can omit one or the other parameter if required, so ?2?food will only set the maximum number of edits to 2, leaving the maximum sequential edits at the default value. If you want to only include the maximum number of sequential edits, then you must include a leading comma in the parameter set, e.g. ?,2?food\nSee Fuzzy Matching for more details.\nDefaulting search terms to fuzzy matching By default LIFTI will treat a search term as an exact word match, however you can configure the index so that any search term (apart from those containing wildcards) will be treated as a fuzzy match.\nWildcard matching Any search term containing * or % will be considered a wildcard match, where:\n* matches zero or more characters % matches any single character. You can use multiple % in a row to indicate an exact number of characters that need to be matched. Examples:\nfoo* would match occurrences of food and football *ing would match drifting and flying %%%ld would match could and mould (but not should, because it has 4 letters before the ld) %%p* matches words starting with any two characters followed by g, then any zero or more characters, e.g. map, caps, duped And (\u0026) The and operator (\u0026) Performs an intersection of two intermediate query results, combining word positions for successful matches.\nFood \u0026 Burger searches for documents containing both \"food\" and \"burger\" at any position, and in any field.\n(Alternatively Food Burger will have the same effect as the default operator between query parts is an \u0026.)\nOr (|) Performs a union of two intermediate query results. Where a document appears in both sets, word positions are combined into one list.\nRestricts results to same field by default: false\nBracketing expressions Brackets can be used to group expressions together.\ne.g. (food \u0026 cake) | (cheese \u0026 biscuit)\nField restrictions (field=...) These allow for restricting searches within a given field.\ntitle=analysis | body=(chocolate \u0026 cake) Searches for documents with \"analysis\" in the title field or both \"chocolate\" and \"cake\" in the body field.\ntitle=analysis food Searches for documents with \"analysis\" in the title field and \"food\" in any field.\nIf your field name contains spaces or other special characters, you can escape it using square brackets [ and ], e.g. [my field]=chocolate.\nSequential text (\"...\") Placing quotes around a search phrase will enforce that the words all appear immediately next to each other in the source text.\n\"cheese burger\" will only match documents that have text containing \"cheese\" followed immediately by \"burger\".\nNear (~ and ~n) The near operator performs a positional intersection of two results based on the position of the word in a field.\nThe ~ operator requires that words must be within 5 words of one another. This can value can be controlled by specifying a number, e.g. ~4 to restrict to only returning results within 4 words of one another.\ncheese ~ cake will return documents containing the words \"cheese\" and \"cake\" in either order, up to 5 words apart, e.g. \"the cake was made with cheese\" and \"I like cheese and cake\" would both match, but \"cake is never to be considered a substitute for cheese\" would not.\nNear following (~\u003e and ~n\u003e) Same as Near (~) except that order is important in the positional intersection.\ncheese ~\u003e cake will match \"cheese and cake\" but not \"cake and cheese\"\nFollowing (\u003e) Same as Near Following (~\u003e) except there are no constraints on how far apart the words can be.\ncheese \u003e cake will match any text where \"cheese\" precedes \"cake\" in a given field.\nScore boosting Wildcard, fuzzy match and exact match search terms can have their resulting scores boosted by adding ^n after them. For example, wild^2 will boost matches of “wild” by 2x.\nEscaping search text Use a backslash \\ when you want to explicitly search for a character that clashes with the query syntax. For example, A\\=B will search for a single token containing exactly “A=B”, rather than attempting to perform a field restricted search.\n","categories":"","description":"The default query parser for an index makes use of a powerful query syntax.\n","excerpt":"The default query parser for an index makes use of a powerful query …","ref":"/lifti/docs/searching/lifti-query-syntax/","tags":"","title":"The LIFTI Query Syntax"},{"body":"First you will need to make sure that the index is deserialized before use, as demonstrated here, and add an index modification hook to serialize the index whenever a new snapshot is created.\n","categories":"","description":"With a bit of configuration you can configure the index to serialize to a backing file whenever changes are made to it.\n","excerpt":"With a bit of configuration you can configure the index to serialize …","ref":"/lifti/docs/serialization/automatic-serialization/","tags":"","title":"Automatic Serialization"},{"body":"index.BeginBatchChange(); await index.AddAsync(1, \"This is some text associated with A: fizz\"); await index.AddAsync(2, \"Some buzz text for B\"); await index.AddAsync(3, \"Text associated with C is both fizz and buzz\"); await index.CommitBatchChangeAsync(); Only once CommitBatchChangeAsync has been called will the new data be available in the index for searching. If a search operation was to have been performed between any of the calls to AddAsync then the previous snapshot would have been used and it would be as if the new documents had not been added yet.\n","categories":"","description":"Each index mutation causes a new immutable snapshot to be generated. You can speed up the indexing process by calling `BeginBatchChange` before mutating the index and `CommitBatchChangeAsync` once all the mutations have been performed.\n","excerpt":"Each index mutation causes a new immutable snapshot to be generated. …","ref":"/lifti/docs/indexing-mutations/batch-mutations/","tags":"","title":"Batch Mutations"},{"body":"Example usage var index = new FullTextIndexBuilder\u003cint\u003e() .WithDefaultTokenization(o =\u003eo .AccentInsensitive(true) // Default .CaseInsensitive(true) // Default .SplitOnPunctuation(true) // Default .SplitOnCharacters('%', '#', '@') .IgnoreCharacters('\u003c', '\u003e') .WithStemming() ) .Build(); TokenizerBuilder methods Text Normalization IgnoreCharacters(char[]) Configures the tokenizer to ignore certain characters as it is parsing input. Ignoring characters will prevent them from acting as split characters, so care needs to be taken that your source text doesn’t words delimited only by ignored characters, otherwise you may end up unexpectedly joining search terms into one. For example, ignoring the ' character will mean that O'Reilly will be tokenized as OReilly, but if your source text also contains she said'hello' then she and saidhello will treated as tokens.\nAccentInsensitive(bool) true: Default The tokenizer will normalize characters with diacritics to common form. e.g. aigües and aigues will be equivalent. Additionally, characters that can be logically expressed as two characters are expanded, e.g. laering will be equivalent to læring.\nfalse: The tokenizer will be accent sensitive. Searching for aigües will not match aigues.\nCaseInsensitive(bool) true: Default The tokenizer will normalize all characters to uppercase. e.g. Cat and cat will be equivalent.\nfalse: The tokenizer will be case sensitive. Searching for Cat will match Cat but not cat.\nWithStemming() Words will be stemmed using an implementation of the Porter Stemmer algorithm. For example, ABANDON, ABANDONED and ABANDONING will all be treated as ABANDON. Currently only English is supported.\nA custom stemmer can be used by implementing an IStemmer and using WithStemming(new YourStemmerImplementation()).\nWord break modifiers A tokenizer will always break words on separator (Char.IsSeparator) or control (Char.IsControl) characters.\nSplitOnPunctuation(bool) true: Default The tokenizer will split words on punctuation characters (e.g. those that match Char.IsPunctuation(char))\nfalse: Only characters explicitly specified using SplitOnCharacters will be treated as word breaks.\nSplitOnCharacters(params char[]) Allows for additional characters to cause word breaks for a tokenizer. E.g. SplitOnCharacters('$', '£').\n","categories":"","description":"Specifies the default tokenization options that should be used when searching or indexing when tokenization options are not explicitly specified for an object type.\n","excerpt":"Specifies the default tokenization options that should be used when …","ref":"/lifti/docs/index-construction/withdefaulttokenization/","tags":"","title":"Default tokenization"},{"body":"FullTextIndexBuilder\u003cTKey\u003e FullTextIndexBuilder requires a single generic type provided to it. This defines the type of the key that documents will be indexed against.\nIn simple cases this will just be a string, Guid, Int32 or UInt32. Indexes can be built with other key types, including composite types, but special care needs to be made when using the binary serializer. See Key Serialization for more information.\nQuick examples Create an index with defaults:\ncase insensitive accent insensitive full LIFTI query syntax for queries (Don’t want this? See WithSimpleQueryParser) no word stemming splitting only on punctuation, whitespace and control characters var index = new FullTextIndexBuilder\u003cint\u003e() .Build(); Enable word stemming:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithDefaultTokenizationOptions(o =\u003e o.WithStemming()) .Build(); With object indexing enabled for a Customer type and stemming only enabled for the Notes property:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithObjectTokenization\u003cCustomer\u003e(o =\u003e o .WithId(c =\u003e c.CustomerId) .WithField(\"Name\", c=\u003ec.Name) .WithField(\"Notes\", c=\u003ec.Notes, fo =\u003e fo.WithStemming()) ) .Build(); ","categories":"","description":"Use a `FullTextIndexBuilder\u003cTKey\u003e` to configure the behavior of your index.\n","excerpt":"Use a `FullTextIndexBuilder\u003cTKey\u003e` to configure the behavior of your …","ref":"/lifti/docs/index-construction/","tags":"","title":"Index Construction"},{"body":"Example usage public class Customer { public int Id { get; set; } public string Name { get; set;} public string ProfileHtml { get; set;} } var index = new FullTextIndexBuilder\u003cint\u003e() .WithObjectTokenization\u003cCustomer\u003e(o =\u003e o .WithKey(c =\u003e c.Id) .WithField(\"Name\", c =\u003e c.Name, scoreBoost: 1.5D) .WithField(\"Profile\", c =\u003e c.ProfileHtml, textExtractor: new XmlTextExtractor()) .WithDynamicFields(\"Tags\", c =\u003e c.TagDictionary, \"Tag_\") .WithDynamicFields( \"Questions\", c =\u003e c.Questions, q =\u003e q.QuestionName, q =\u003e q.QuestionResponse, \"Question_\", scoreBoost: 1.8D) .WithScoreBoosting( boost =\u003e boost .Freshness(c =\u003e c.UpdatedDate, 2D) .Magnitude(c =\u003e c.Rating, 2D)) ) .Build(); await index.AddAsync(new Customer { ... }); WithKey Each object configured against the index must have a key of the same type as the index’s key. WithKey defines how this key is read from the object.\nWithField An object can be configured with one static fields that are known at compile time. The WithField method overloads allow for static fields to be defined.\nname The unique name of the field in the index. This has two main uses subsequently:\nIn search results you are provided with a breakdown of where matches were found - the name of the field is included in this information. When querying, you can restrict a part of the search to a specific field, e.g. Profile=food will only match the word food in the Profile field, and no others. See Searching for more information. fieldTextReader A function capable of extracting the raw text from the object. Supported function definitions:\nFunc\u003cT, string\u003e Func\u003cT, IEnumerable\u003cstring\u003e\u003e And their async equivalents:\nFunc\u003cT, Task\u003cstring\u003e\u003e Func\u003cT, Task\u003cIEnumerable\u003cstring\u003e\u003e\u003e tokenizationOptions Equivalent to WithDefaultTokenization but for use exclusively with this field. Left null, the default tokenizer for the index will be used.\ntextExtractor Equivalent to WithTextExtraction but for use exclusively use with this field. Left null, the default text extractor for the index will be used.\nthesaurusOptions Equivalent to WithDefaultThesaurus but for use exclusively with this field. Left null, the default thesaurus builder for the index will be used.\nscoreBoost The multiplier to apply to the score of this field when ranking results. The default value of 1 is equivalent to no boosting.\nWithDynamicFields In addition to the static fields configured using WithField, it is possible to configure dynamic fields that are not known at compile time. The WithDynamicFields overloads allow for dynamic field readers to be defined, each of which will be invoked to retrieve the field names for the object being indexed.\nImportant: LIFTI only supports a maximum of 255 unique field names per index, whether they are dynamic or defined statically using WithField. Because dynamic fields are not known at compile time, it is possible to exceed this limit if you are not careful. If you do exceed this limit, an exception will be thrown when you try to index an object.\ndynamicFieldReaderName The unique name of the dynamic field reader. Dynamic fields are registered in the index against this name so that when the index is deserialized, the dynamic fields can be rehydrated against the correct configuration.\ndynamicFieldReader A function capable of extracting the dynamic field information from the object type T.\nYou can provide a function that returns a dictionary of name/value pairs, where the key becomes the field name and the value the text being indexed against it:\nFunc\u003cT, IDictionary\u003cstring, string\u003e?\u003e Func\u003cT, IDictionary\u003cstring, IEnumerable\u003cstring\u003e\u003e\u003e Or you can provice a function that returns a collection of child objects:\nFunc\u003cT, ICollection\u003cTChild\u003e?\u003e Func\u003cT, ICollection\u003cTChild\u003e?\u003e These last two overloads also require you provide two more delegates via the getFieldName and getFieldText parameters. These delegates are used to extract the field name and text from each child object.\nfieldNamePrefix The prefix to use when constructing the field name. This is useful when the dynamic fields can produce the same field name as a static field, or a dynamic field from another dynamic field reader.\nOther WithDynamicFields parameters The tokenizationOptions, textExtractor, thesaurusOptions and scoreBoost parameters are equivalent to their WithField counterparts.\nWithScoreBoosting Configures the score boosting options for the object type. These allow you to promote documents associated to objects based on related data.\nFreshness Freshness boosting allows you to boost results based on a date associated to the object. For example, assuming all the documents have exactly the same text and a multiplier of 3 is specified, then the score of the newest document will be 3 times higher than the oldest.\nMagnitude Magnitude boosting allows you to boost results based on a numeric value associated to the object. For example, if you used this with a “star rating” property, documents with a higher rating will be more likely to appear nearer the top of search results.\nIndexing multiple object types It is possible to index multiple types against an index, however you need to consider a couple of constraints.\n1. Extracted keys need to be unique across all object types. If you are indexing disparate object types with overlapping ids, you could consider using a composite key type in the index, e.g.\npublic enum EntryKind { Customer, Product } var index = new FullTextIndexBuilder\u003c( EntryKind kind, int id )\u003e() .WithObjectTokenization\u003cCustomer\u003e(o =\u003e o .WithKey(c =\u003e (EntryKind.Customer, c.Id)) .WithField(\"CustomerName\", c =\u003e c.Name) ) .WithObjectTokenization\u003cProduct\u003e(o =\u003e o .WithKey(p =\u003e (EntryKind.Product, p.Id)) .WithField(\"ProductName\", p =\u003e p.Name) ) .Build(); To serialize an index with a composite key, you will need to use a custom IKeySerializer - see Key Serialization.\n2. Field names must be unique across all object types You will get an error if you try to register the same name twice, even in separate WithObjectTokenization calls.\n","categories":"","description":"Configure the index to accept a strongly typed object when indexing content.\n","excerpt":"Configure the index to accept a strongly typed object when indexing …","ref":"/lifti/docs/index-construction/withobjecttokenization/","tags":"","title":"Object tokenization"},{"body":"LIFTI’s query execution logic employs a strategic approach to optimize query performance, prioritizing the execution of query parts based on their calculated weights. This weight represents the relative cost and effectiveness of executing a particular query part in relation to the overall document set. By assigning these weights, LIFTI aims to minimize the number of documents involved early in the query execution, thereby reducing the computational load and improving efficiency.\nScoring mechanism overview General Principle: Each query part is assigned a “weight” based on its expected execution cost and the number of documents it is likely to involve. The objective is to execute less costly parts first, reducing the document set size early in the process.\nWeighting Calculations for Different Query Parts:\nExactWordQueryPart: Uses inverse document count. Weight = Matching Document Count / Total Document Count. Lower weights will result for words bringing in fewer documents. WildcardQueryPart: A complex calculation involving the count of text matches, multi-character, and single-character wildcard matches, with different multipliers. Weight is reduced if the first query part is a text match, and increased it it has a leading multi-character match. FuzzyMatchQueryPart: Based on the ExactWordQueryPart’s weighting, adding a factor for the number of edits allowed. Weight increases with more permissible edits. AdjacentWordsQueryPart: Assumes the score of the first part of the query, adjusted by the inverse of the number of parts. Intersection Query Parts (AndQueryPart, PrecedingNearQueryPart, NearQueryPart, PrecedingQueryPart): Promotes parts based on the lowest scoring part of the intersection, encouraging execution of the cheapest part first. OrQueryOperator: A union operation always requires both sides to be evaluated, so weight = Left Score + Right Score. FieldFilterQueryOperator: Applies additional filtering, thus promoted. Weight = Child Part Score * 0.5. BracketedQueryPart: Reflects the score of the child part. Execution strategy The execution order is determined by these weightings, with lower weights prioritized. This approach ensures that the query processor can efficiently filter and score documents, avoiding unnecessary computations on documents that would later be excluded. This system is especially beneficial in queries with multiple parts, where early reduction in document set size can lead to significant performance improvements.\nExecution plans To get more insight into how a query is executed, including the weighting scores that were calculated you can get LIFTI to generate the actual execution plan for a query.\n// Execute the query, indicating that timings and other details should be included var results = index.Search(\"find something\", QueryExecutionOptions.IncludeExecutionPlan); // Calculate and return the execution plan details var actualExecutionPlan = results.GetExecutionPlan(); See Understanding LIFTI query execution plans for more details.\n","categories":"","description":"LIFTI attempts to optimize the order that query parts are executed to make queries as efficient as possible.\n","excerpt":"LIFTI attempts to optimize the order that query parts are executed to …","ref":"/lifti/docs/searching/query-execution/","tags":"","title":"Query execution"},{"body":"LIFTI uses a version of the Okapi BM25 algorithm to score search results. At the simplest level this means that search results will come back ordered by relevance. Fuzzy matching affects the scores for search results depending on the distance between the target word and the search term.\nOnce nice feature of LIFTI is that in you also get each field scored independently. The overall score for a document is just a sum of these, but you could easily just re-order the results by one field over another should you so wish.\nISearchResults\u003cT\u003e.OrderByField returns a new instance of ISearchResults\u003cT\u003e with the results re-ordered considering only the scores for a single field:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithObjectTokenization\u003cCustomer\u003e(o =\u003e o .WithKey(c =\u003e c.Id) .WithField(\"Name\", c =\u003e c.Name) .WithField(\"Profile\", c =\u003e c.ProfileHtml, textExtractor: new XmlTextExtractor()) ) .Build(); await index.AddAsync(new Customer { Id = 1, Name = \"Joe Bloggs\", ProfileHtml = \"\u003ca\u003eSomething else something\u003c/a\u003e\" }); await index.AddAsync(new Customer { Id = 2, Name = \"Joe Something\", ProfileHtml = \"\u003ca\u003eSomething else\u003c/a\u003e\" }); // Searching for \"Something\" will result in ID 2 being ordered before ID 1. // \"Something\" appears twice in each document overall, however document 2 has fewer words, therefore the matches // are more statistically significant. var results = index.Search(\"something\"); PrintSearchResults(results); // Output // 2 // 1 // But if you only consider the \"Profile\" field, then the Something only appears once in document 2, // therefore document 1 will come first. results = results.OrderByField(\"Profile\"); PrintSearchResults(results); // Output // 1 // 2 Score boosting You can boost scores in a number of ways:\nBoosting search terms as part of the query: thanks^1.5. Boosting fields associated to an object: .WithField(\"Name\", c =\u003e c.Name, scoreBoost: 1.5D). Boosting objects based on a freshness date, e.g. the date it was last updated. Boosting objects based on a magnitude value, e.g. a star rating. ","categories":"","description":"Explains how  the results provided in `ISearchResults\u003cT\u003e` are ordered, and how LIFTI calculates its scores.\n","excerpt":"Explains how  the results provided in `ISearchResults\u003cT\u003e` are ordered, …","ref":"/lifti/docs/searching/search-results/scoring/","tags":"","title":"Search result scoring"},{"body":"Fuzzy matches can be explicitly searched for using the LIFTI query syntax, or implied as the default for searches by configuring the index.\nLIFTI uses Levenshtein distance to perform fuzzy matches between a search term and tokens in the index. The distance between two words is the number of edits that are required to match them, including:\ninsertions: fid would match find deletions: foood would match food substitutions: frnd would match find transpositions: fnid would match find - Transpositions are a special case, because although two characters are affected, it is considered a single edit. The resulting Levenshtein distance between any matched term and the search term is used to reduce the score of the match. This means that documents containing words that are closer matches will typically be surfaced higher up in the search results.\nConfiguration To prevent a combinatorial explosion of potential matches, LIFTI provides two control mechanisms for fuzzy matching:\nMaximum number of edits - the total number of edits that can be used in any potential match. The default for this value is calculated as search term length/2 which allows for a larger number of edits for longer search terms. Search terms of just a single character will not allow any edits, as the resulting value will be zero (the formula is an integer calculation). Maximum number of sequential edits - the maximum number of edits that can be found sequentially in any potential match. The default for this value is calculated as max(1, search term length/4). This default allows for a growing number of sequential edits, however this will never drop below a value of one. When providing your own overrides for these calculations, be aware that if your configuration for either results in a value of zero, then the fuzzy match will become an exact match, as no edits will be allowed.\nExample With a max edits of 3 and max sequential edits of 1:\nfeed will not match food because it requires two sequential edits redy will not match friendly because it requires 4 insertions Default values can be configured at the index level, and can either be expressed as a static value, or a value calculated from the length of the search term.\n","categories":"","description":"Fuzzy matching provides a mechanism by which you can search for words that are close to a search term, in terms of the number of differences between them.\n","excerpt":"Fuzzy matching provides a mechanism by which you can search for words …","ref":"/lifti/docs/searching/fuzzy-matching/","tags":"","title":"Fuzzy Matching"},{"body":"Indexing text As shown in this example, if all you have is a key and text to be indexed for it, you can just make use one of the AddAsync overloads that operate on strings - there is no need to construct any artificial objects in order to populate the index.\nEach of these methods will use the default text extraction and tokenization configured for the index and the default field id, IFullTextIndex.FieldLookup.DefaultField.\nTask AddAsync(TKey key, string text) Adds a document to the index treating the single string as the complete document text.\nTask AddAsync(TKey key, IEnumerable\u003cstring\u003e text) Adds a document to the index with multiple text fragments. Each fragment is considered to be fragments of the same text, i.e. the index and offset of tokens increments across the elements in the IEnumerable\u003cstring\u003e.\nIt’s worth noting that each fragment is processed independently, so an implicit word break exists between element. This means that AddAsync(1, new[ \"a\", \"b\" ]) will index two words (a and b) whereas if the two strings had been naively concatenated together, only one (ab) would, as there was no word break between them.\nIndexing Objects In order to index an object against the index it needs to have first been configured when the index was built, using WithObjectTokenization. This allows for multiple properties of a single object to be extracted as different fields of the same document.\nSee the Indexing objects quick start for an example of this in action.\nTask AddAsync\u003cTObject\u003e(TObject item) Adds a single document to the index.\nTask AddRangeAsync\u003cTObject\u003e(IEnumerable\u003cTObject\u003e items) Adds a set of documents to the index in a single mutation. This is more efficient than making multiple calls to AddAsync\u003cTObject(TObject item)\u003e unless a batch mutation has already been manually started.\n","categories":"","description":"Once an index has been constructed, it can be populated using the various `AddAsync` methods.\n","excerpt":"Once an index has been constructed, it can be populated using the …","ref":"/lifti/docs/indexing-mutations/","tags":"","title":"Indexing Data"},{"body":"RemoveAsync(TKey key) Removes all indexed data for the given item key.\nRemoval is considered an index mutation in the same way that adding is, and batches of changes can be sped up by using the BeginBatchChange and CommitBatchChangeAsync methods.\n","categories":"","description":"Data can be removed from an index using the `RemoveAsync` method.\n","excerpt":"Data can be removed from an index using the `RemoveAsync` method.\n","ref":"/lifti/docs/indexing-mutations/removing-data/","tags":"","title":"Removing Data"},{"body":"When you have configured an index to use the simple query parser you can no longer make use of the full LIFTI query syntax in your queries, however you can still configure the simple query parser to treat all search terms as fuzzy matches.\nSearch terms are simply combined together with ands or ors, depending on your configuration, and punctuation is stripped out as per your index tokenization rules.\n","categories":"","description":"When you want to keep your queries simple, always searching for documents containing all (or just some) search terms, you can configure an index to use the simple query parser.\n","excerpt":"When you want to keep your queries simple, always searching for …","ref":"/lifti/docs/searching/simple-queries/","tags":"","title":"Simple Queries"},{"body":"A FullTextIndex class exposes a FieldLookup property of type IIndexedFieldLookup that can be used to query the index for information about the fields that have been indexed.\nIIndexedFieldLookup exposes the following methods:\nDefaultField The id of the default field used when an IFullTextIndex{T}.AddAsync(T, string, System.Threading.CancellationToken) overload has been used, as opposed to indexing text read from properties of object.\nGetFieldForId(byte id) Gets the configured name for a field id.\nGetFieldInfo(string fieldName) Gets the configuration required for indexing a named field, including the Tokenization.TextExtraction.ITextExtractor and Tokenization.IIndexTokenizer instances to use when processing the field’s text.\nIndexedFieldDetails This abstract class contains information about a field that has been configured for indexing.\nProperties Id: Gets the id of the field. Name: Gets the name of the field. ObjectType: Gets the type of the object the field is registered for. FieldKind: Gets the kind of field this instance represents, either FieldKind.Static or FieldKind.Dynamic. TextExtractor: Gets the ITextExtractor used to extract sections of text from this field. Tokenizer: Gets the IIndexTokenizer that should be used when tokenizing text for the field. Thesaurus: Gets the IThesaurus that should be used to expand tokens when processing text for this field. DynamicFieldReaderName: Gets the name of the dynamic field reader that generated this field. If this field is not a dynamic field, this will be null. Methods ReadAsync(object item, CancellationToken cancellationToken): Reads the text for the field from the specified object. The object must be of the type specified by the ObjectType property. IsKnownField(Type objectType, string fieldName) Returns true if the given field name is known to the index and associated to the given object type, whether statically defined at index creation, or dynamically registered during indexing.\nAllFieldNames Gets the names of all fields configured in the index, including any dynamic fields that have been registered during the indexing of objects.\n","categories":"","description":"You can query the index to get information about the fields that have been indexed.\n","excerpt":"You can query the index to get information about the fields that have …","ref":"/lifti/docs/searching/field-information/","tags":"","title":"Field Information"},{"body":"FullTextIndexBuilder\u003cTKey\u003e WithDuplicateKeyBehavior(DuplicateKeyBehavior duplicateKeyBehavior)\nDuplicateKeyBehavior.Replace: Default The document associated to the key will first be removed from the index, then indexed DuplicateKeyBehavior.ThrowException: An exception will be thrown. You can use this if you’re not expecting keys to be re-indexed and want some indication that your code isn’t behaving correctly. Example usage var index = new FullTextIndexBuilder\u003cint\u003e() .WithDuplicateKeyBehavior(DuplicateKeyBehavior.ThrowException) .Build(); ","categories":"","description":"Configure how the index should behave when indexing an item that is already present in the index.\n","excerpt":"Configure how the index should behave when indexing an item that is …","ref":"/lifti/docs/index-construction/withduplicatekeybehavior/","tags":"","title":"Managing duplicate keys"},{"body":"Configuring the default LIFTI QueryParser FullTextIndexBuilder\u003cTKey\u003e WithQueryParser(Func\u003cQueryParserBuilder, QueryParserBuilder\u003e optionsBuilder)\nBy default LIFTI parses query text using the LIFTI query syntax. The behavior of the parser can be tweaked using this overload.\nProviding a complete IQueryParser implementation FullTextIndexBuilder\u003cTKey\u003e WithQueryParser(IQueryParser queryParser)\nAllows you to provide your own implementation of IQueryParser capable of parsing text into an IQuery.\nTo see an example of a custom IQueryParser implementation, see this blog post.\nQueryParserBuilder options WithDefaultJoiningOperator QueryParserBuilder.WithDefaultJoiningOperator(QueryTermJoinOperatorKind joiningOperator) The default joining operator for queries is and. This means that without explicitly adding in an \u0026 or | to a LIFTI query, \u0026 will be assumed, and all search terms must match in a document. This method allows you to choose between and and or as the default joining operator.\nAssumeFuzzySearchTerms QueryParserBuilder.AssumeFuzzySearchTerms() When used, uses fuzzy matching for any parsed search terms that don’t contain wildcard operators, i.e. you don’t need to prefix search terms with ?.\nWithFuzzySearchDefaults QueryParserBuilder.WithFuzzySearchDefaults(ushort maxEditDistance, ushort maxSequentialEdits) Configures the default parameters for a fuzzy search when not provided explicitly as part of the query. This overload provides static values to use for the maximum edit distance and maximum sequential edits for a fuzzy search.\nQueryParserBuilder.WithFuzzySearchDefaults(Func\u003cint, ushort\u003e maxEditDistance, Func\u003cint, ushort\u003e maxSequentialEdits) Configures the default parameters for a fuzzy search when not provided explicitly as part of the query. This overload allows for the maximum edit distance and maximum sequential edits for a fuzzy search to be calculated from the length of a search term.\nIf either of these functions returns zero, then fuzzy matching will be disabled for the search term.\nBy default maxEditDistance is calculated as termLength / 3, which means that fuzzy matching will be disabled for any search term less than 2 characters. The default for maxSequentialEdits is Max(1, termLength / 4), which means that no matter how short the search term, at least one sequential edit is allowed.\nSee Fuzzy Matching.\nWithQueryParserFactory QueryParserBuilder.WithQueryParserFactory(Func\u003cQueryParserOptions, IQueryParser\u003e) Given a QueryParserOptions, creates the implementation of IQueryParser. You can use this to provide a custom query parsing strategy.\nExample usage var index = new FullTextIndexBuilder\u003cint\u003e() .WithQueryParser(o =\u003e o.AssumeFuzzySearch()) .Build(); ","categories":"","description":"Configure how the LIFTI query parser should operate for the index.\n","excerpt":"Configure how the LIFTI query parser should operate for the index.\n","ref":"/lifti/docs/index-construction/withqueryparser/","tags":"","title":"Query parser configuration"},{"body":"There are two ways to query a FullTextIndex, searching with a query string and executing a manually constructed Query.\nSearching with text index.Search(\"find something\"); This approach uses the IQueryParser implementation configured for the index to parse the query text into a Query object, which is then executed.\nThe default IQueryParser that is configured against an index parses the LIFTI query syntax, which is a fairly flexible way of expressing a query. If you want to swap out this parser with a custom implementation, you can do so when building the index using WithQueryParser option.\nSearching with a Query You can manually construct a Query using any combination of IQueryParts, but take care to normalize any text to match in the same way that it has been indexed. You can do this using either the IIndexTokenizer for the index, or if specific tokenization rules have been configured for a field, then the tokenizer for that field:\nvar tokenizer = index.DefaultTokenizer; var query = new Query( new AndQueryPart( new ExactWordQueryPart(tokenizer.Normalize(\"hello\")), new ExactWordQueryPart(tokenizer.Normalize(\"there\")))); Obtaining query execution plans By specifying QueryExecutionOptions.IncludeExecutionPlan when searching, LIFTI will collect timing information during the execution of the various query parts:\nindex.Search(\"find something\", QueryExecutionOptions.IncludeExecutionPlan); This enables ISearchResults.GetExecutionPlan to return the actual execution plan for the query. If QueryExecutionOptions.IncludeExecutionPlan is not specified, GetExecutionPlan returns a placeholder execution plan.\nSee Understanding LIFTI query execution plans for more details.\n","categories":"","description":"How to search against a LIFTI index\n","excerpt":"How to search against a LIFTI index\n","ref":"/lifti/docs/searching/","tags":"","title":"Searching"},{"body":"Defining a thesaurus A thesaurus is a tool used to organize and categorize words based on their meanings and relationships. It can be built using the ThesaurusBuilder class, which allows you to add both synonyms, hyponyms and hypernyms.\nWithSynonyms(ICollection\u003cstring\u003e synonyms) The WithSynonyms method is used to instruct the thesaurus to expand any of the given synonyms when one of them indexed. For example, if you add the synonyms dog, doggy, puppy, and pup to the thesaurus and include the terms \"I love my doggy\" and \"We got a new puppy today\" in the index, a search for \"dog\" would return both of these entries because doggy and puppy are synonymous with dog.\nWithHyponyms(string word, ICollection\u003cstring\u003e hyponyms) The WithHyponyms method is used to instruct the thesaurus to expand the search to include any words that are more specific or narrower in meaning compared to the given term. These narrower terms are known as hyponyms.\nFor example, if you add the hyponyms poodle and beagle to the thesaurus for the term dog using:\nWithHyponyms(\"dog\", \"poodle\", \"beagle\"); searching for \"dog\" would return entries that contain poodle and beagle because they are hyponyms of dog. searching for \"poodle\" or \"beagle\" will return only entries that explicitly contain those terms - other mentions of dog, e.g. “Dogs are a type of domestic animal” will not be returned WithHypernyms(string word, ICollection\u003cstring\u003e hypernyms) The WithHypernyms method is used to instruct the thesaurus to expand the search to include any words that are more general or broader in meaning compared to the given terms. These broader terms are known as hypernyms.\nFor example, if you add the hypernyms mammal and canine to the thesaurus for the term dog:\nWithHypernyms(\"dog\", \"mammal\", \"canine\"); searching for \"mammal\" would return entries that contain dog because mammal is a hypernym of dog. searching for \"dog\" will return only entries that explicitly contain dog - other mentions of mammal, e.g. “Mammals are warm blooded” will not be returned Default thesaurus FullTextIndexBuilder\u003cTKey\u003e WithDefaultThesaurus(Func\u003cThesaurusBuilder, ThesaurusBuilder\u003e thesaurusBuilder)\nBuilds the default thesaurus to use for the index. This thesaurus will be used for text added directly to the index and also fields that have no explicit thesaurus defined for them.\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithDefaultThesaurus(o =\u003e o.WithHyponyms(\"dog\", \"poodle\", \"beagle\")) .Build(); Field-level thesaurus A thesaurus can be configured specifically for an object’s field - in this example the hyponyms will only be applied to the Content field:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithObjectTokenization\u003cBook\u003e( o =\u003e o .WithKey(i =\u003e i.Id) .WithField(\"Content\", i =\u003e i.Content, thesaurusOptions: o =\u003e o.WithHyponyms(\"dog\", \"poodle\", \"beagle\") .WithField(\"Title\", i =\u003e i.Title)); Interplay between the thesaurus and tokenizer The values in a thesaurus are automatically passed through the tokenizer for the relevant field. For example, an index constructed as:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithDefaultTokenizer(o =\u003e o.CaseInsensitive()) .WithDefaultThesaurus(o =\u003e o.WithSynonyms(\"conduct\", \"conduction\")) .WithObjectTokenization\u003cBook\u003e( o =\u003e o .WithKey(i =\u003e i.Id) .WithField(\"Content\", i =\u003e i.Content, tokenizationOptions: o =\u003e o.WithStemming()) .WithField(\"Title\", i =\u003e i.Title, tokenizationOptions: o =\u003e o.CaseInsensitive(false))); Would end up with 3 variations of the thesaurus values:\nOnce for the default tokenizer with case insensitivity applied Once for the “Content” with stemming applied to the words Once for the “Title” field without case insensitivity applied ","categories":"","description":"Prescribes how the index should treat terms as synonymous when they are being added to the index.\n","excerpt":"Prescribes how the index should treat terms as synonymous when they …","ref":"/lifti/docs/index-construction/withdefaultthesaurus/","tags":"","title":"Thesaurus synonyms"},{"body":"You can manually construct a Query using any combination of IQueryParts, but take care to normalize any text to match in the same way that it has been indexed. You can do this using either the IIndexTokenizer for the index, or if specific tokenization rules have been configured for a field, then the tokenizer for that field:\nvar tokenizer = index.DefaultTokenizer; var query = new Query( new AndQueryOperator( new ExactWordQueryPart(tokenizer.Normalize(\"hello\")), new ExactWordQueryPart(tokenizer.Normalize(\"there\")))); Query Parts IQueryParts come in two flavors:\nOperators - these contain other IQueryParts, combining the results that they return according to certain rules, e.g. AndQueryPart and OrQueryPart Textual - these work the IIndexNavigator to query the index for matches appropriate to them, e.g. ExactWordQueryPart, FuzzyMatchQueryPart. Textual query parts ExactWordQueryPart(string word) Searches the index for words that exactly match word.\nFuzzyMatchQueryPart(string word, ushort maxEditDistance = 4, ushort maxSequentialEdits = 1) ? in LIFTI query syntax\nPerforms a fuzzy match against the index.\nmaxEditDistance: The maximum of edits allowed for any given match. The higher this value, the more divergent matches will be. maxSequentialEdits The maximum number of edits that are allowed to appear sequentially. By default this is 1, which forces matches to be more similar to the search criteria WildcardQueryPart(IReadOnlyList\u003cWildcardQueryFragment\u003e fragments) * and % in LIFTI query syntax\nA WildcardQueryPart consists of multiple WildcardQueryFragments that are processed sequentially to match tokens in the index. They can be constructed using the following methods:\nWildcardQueryFragment.MultiCharacter() - matches zero or more characters in the index. WildcardQueryFragment.SingleCharacter() - matches any single character in the index. WildcardQueryFragment.CreateText(string text) - exact matches a fragment of text at whatever point has been reached in the index. For example:\nvar wildcard = new WildcardQueryPart(new[] { WildcardQueryFragment.SingleCharacter(), WildcardQueryFragment.SingleCharacter(), WildcardQueryFragment.CreateText(\"d\") }) Would translate to the LIFTI query %%d, matching any words that start with any two letters followed by a d.\nStructural query parts AndQueryOperator(IQueryPart left, IQueryPart right) \u0026 in LIFTI query syntax\nIntersects the results of two query parts. In other words, only matches that appear on both sides will be returned.\nOrQueryOperator(IQueryPart left, IQueryPart right) | in LIFTI query syntax\nUnions the results of two query parts. In other words, a deduplicated set of matches on both sides will be returned.\nBracketedQueryPart(IQueryPart statement) ( and ) in LIFTI query syntax\nThis can be used to group other query parts together, ensure they are executed in the right order.\nAdjacentWordsQueryPart(IReadOnlyList\u003cIQueryPart\u003e matches) \" in LIFTI query syntax\nA query part requiring that a series of matches must appear in a document in sequence.\nFieldFilterQueryOperator(string fieldName, byte fieldId, IQueryPart statement) field= in LIFTI query syntax\nRestricts the resulting document matches to only those that include matching tokens in a specific field.\nNearQueryOperator(IQueryPart left, IQueryPart right, int tolerance = 5) ~n in LIFTI query syntax\nProduces an intersection of two IQueryParts, restricting an document’s field matches such that the locations are close to one another.\nDocuments that result in no field matches are filtered out.\nPrecedingNearQueryOperator(IQueryPart left, IQueryPart right, int tolerance = 5) ~n\u003e in LIFTI query syntax\nProduces an intersection of two IQueryParts, restricting an document’s field matches such that the locations of the first appear before the locations of the second and within a specified tolerance.\nDocuments that result in no field matches are filtered out.\nPrecedingQueryOperator(IQueryPart left, IQueryPart right) \u003e in LIFTI query syntax\nProduces an intersection of two IQueryParts, restricting an document’s field matches such that the locations of the first appear before the locations of the second.\nDocuments that result in no field matches are filtered out.\n","categories":"","description":"Instead of using a query parser to interpret your query, you can manually construct a `Query` object and execute it against the index.","excerpt":"Instead of using a query parser to interpret your query, you can …","ref":"/lifti/docs/searching/manually-constructing-queries/","tags":"","title":"Manually Constructing Query Objects"},{"body":"When processing a search query, LIFTI leverages a class called IndexNavigator which allows for a character-by-character navigation of the index.\nYou can use an IndexNavigator to do the same thing yourself. The example below demonstrates the following methods:\nIIndexNavigator.Process Navigates (forward only) the nodes in the index. IIndexNavigator.GetExactMatches Gets all the matches at the current location in the index. IIndexNavigator.GetExactAndChildMatches Gets the exact matches and any matches in subsequent child nodes. This is the equivalent to a wildcard search. IIndexNavigator.EnumerateIndexedTokens Enumerates the words (tokens) that were indexed under the current location. This essentaially allows for a reverse-engineering of words stored in the index, albeit in their index normalized form. public static async Task RunAsync() { // Create a full text index with default settings var index = new FullTextIndexBuilder\u003cstring\u003e().Build(); // Index some sample data await index.AddAsync(\"Item1\", \"Catastrophe\"); await index.AddAsync(\"Item2\", \"Casualty\"); await index.AddAsync(\"Item3\", \"Cat\"); // To programatically search the index, create an index navigator instance // from the index snapshot. using (var navigator = index.CreateNavigator()) { // Navigate through the letters 'C' and 'A' (these will be the characters in their // *index normalized* form) navigator.Process(\"CA\".AsSpan()); // There will be no exact matches at the current position in the index, but 3 matches // when considering child matches, i.e. words starting with \"ca\" // Writes: Exact matches: 0 Exact and child matches: 3 WriteMatchState(navigator); // Navigating through the 'T' of Catastrophe and Cat, but not Casualty navigator.Process('T'); // Writes: Exact matches: 1 Exact and child matches: 2 WriteMatchState(navigator); // Use EnumerateIndexedTokens to reverse-engineer the words that have been indexed // under the current location in the index, in their normalized form. // Writes: // CAT // CATASTROPHE foreach (var token in navigator.EnumerateIndexedTokens()) { Console.WriteLine(token); } // The Process method returns true if navigation was successful, and false otherwise: // Writes: True Console.WriteLine(navigator.Process('A')); // Writes: False Console.WriteLine(navigator.Process(\"ZOOOOM\")); } } public static void WriteMatchState(IIndexNavigator navigator) { Console.WriteLine($@\"Exact matches: {navigator.GetExactMatches().Matches.Count} Exact and child matches: {navigator.GetExactAndChildMatches().Matches.Count}\"); } ","categories":"","description":"You can use an IndexNavigator to navigate the index character by character.\n","excerpt":"You can use an IndexNavigator to navigate the index character by …","ref":"/lifti/docs/searching/using-the-index-navigator/","tags":"","title":"IndexNavigator"},{"body":"For example, the text being indexed may be an XML or HTML document and you may only want to index the text content of the elements:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithTextExtraction\u003cXmlTextExtractor\u003e() .Build(); Text extraction is only applied when indexing text, i.e. calls to the IFullTextIndex.AddAsync overloads. When searching, text extraction is never applied to any query text.\n","categories":"","description":"Text extraction is the process by which fragments of text are lifted from a larger body of text prior to tokenization. \n","excerpt":"Text extraction is the process by which fragments of text are lifted …","ref":"/lifti/docs/index-construction/withtextextraction/","tags":"","title":"Document text extraction"},{"body":"Given an index:\n// Create a full text index with default settings var index = new FullTextIndexBuilder\u003cint\u003e().Build(); // Index some sample data await index.AddAsync(1, \"This is some text associated with A: fizz\"); await index.AddAsync(2, \"Some buzz text for B\"); await index.AddAsync(3, \"Text associated with C is both fizz and buzz\"); You can serialize it to a stream using the Lifti.Serialization.Binary.BinarySerializer class:\nvar serializer = new BinarySerializer\u003cint\u003e(); using var stream = new MemoryStream(); // Serialize the index await serializer.SerializeAsync(index, stream, disposeStream: false); // Reset the stream back to the beginning so we can deserialize from it stream.Position = 0; After you have created a new index instance, you can use the BinarySerializer class again to bring its state in line with the serialized index:\n// Deserialize the index into a new instance var newIndex = new FullTextIndexBuilder\u003cint\u003e().Build(); await serializer.DeserializeAsync(newIndex, stream, disposeStream: false); // Prove that the new index has the same contents // Emits: 3 documents contain text in the new index var matches = newIndex.Search(\"text\"); Console.WriteLine($\"{matches.Count()} documents contain text in the new index\"); If you want to understand how the binary data is laid out, you can have a look at the Serialization Format reference page.\nChanging index definitions Adding fields Adding fields to an index definition is supported.\nConsider an index defined as:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithObjectTokenization\u003cCustomer\u003e(o =\u003e o .WithKey(c =\u003e c.Id) .WithField(\"Name\", c =\u003e c.Name) ) .Build(); A static field called Name is defined with the id 1. If you serialize this index, and then change the index definition to:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithObjectTokenization\u003cCustomer\u003e(o =\u003e o .WithKey(c =\u003e c.Id) .WithField(\"Name\", c =\u003e c.Name) .WithField(\"Notes\", c =\u003e c.Notes) ) .Build(); A new field called Notes is defined with the id 2. Deserializing the output from the first definition will work fine.\nEven if field order is changed, such that Name became field id 2, the deserialization will still work. The serialization process is smart enough to map the old field id to the new field id.\nRemoving and renaming fields This is not supported. If you remove or rename a field, the deserialization process will fail.\n","categories":"","description":"A LIFTI index can be serialized to a stream, and deserialized at a later date.\n","excerpt":"A LIFTI index can be serialized to a stream, and deserialized at a …","ref":"/lifti/docs/serialization/","tags":"","title":"Serialization"},{"body":"Configuring the SimpleQueryParser FullTextIndexBuilder\u003cTKey\u003e WithSimpleQueryParser()\nFullTextIndexBuilder\u003cTKey\u003e WithSimpleQueryParser(Func\u003cQueryParserBuilder, QueryParserBuilder\u003e optionsBuilder)\nIf you don’t want to be querying against the index using the full LIFTI query syntax then you can use this method to query using simplified queries.\nYou can optionally configure the query parser using the QueryParserBuilder, as you can with WithQueryParser: QueryParserBuilder options.\nExample usage var index = new FullTextIndexBuilder\u003cint\u003e() .WithSimpleQueryParser() .Build(); var index = new FullTextIndexBuilder\u003cint\u003e() .WithSimpleQueryParser(o =\u003e o.AssumeFuzzySearch()) .Build(); ","categories":"","description":"You can use a simple query parser when you don't want queries to make use of the full LIFTI query syntax.\n","excerpt":"You can use a simple query parser when you don't want queries to make …","ref":"/lifti/docs/index-construction/withsimplequeryparser/","tags":"","title":"Using the simple query parser"},{"body":"Let’s say that for some reason you needed to stem every indexed token so that it was at most 3 characters long:\npublic class FirstThreeLettersStemmer : IStemmer { public bool RequiresCaseInsensitivity =\u003e false; public bool RequiresAccentInsensitivity =\u003e false; public void Stem(StringBuilder builder) { if (builder.Length \u003e 3) { builder.Length = 3; } } } RequiresCaseInsensitivity and RequiresAccentInsensitivity are hints used by the index at creation time that force it to enable case/accent sensitivity. Case insensitivity means that any text passed to your stemmer will already be uppercase. Accent insensitivity means that accents will automatically be stripped prior to being sent to the stemmer.\nOnce you’ve got your stemmer implemented, you just need to give it to the FullTextIndexBuilder:\nvar index = new FullTextIndexBuilder\u003cint\u003e() .WithDefaultTokenization(o =\u003e o.WithStemming(new FirstThreeLettersStemmer())) .Build(); ","categories":"","description":"You can implement a custom stemmer if the default English Porter stemmer doesn't meet your needs.\n","excerpt":"You can implement a custom stemmer if the default English Porter …","ref":"/lifti/docs/custom-stemmers/","tags":"","title":"Custom stemmers"},{"body":"Overview The QueryExecutionPlan class represents the execution strategy for a given query. It includes information about the sequence of operations, their timings, and the number of documents affected at each stage of the query.\nQuery execution plan nodes Node properties The execution plan is structured as a tree of QueryExecutionPlanNode instances, each representing a part of the query execution process. Each QueryExecutionPlanNode includes details about its part of the query execution:\nExecutionOrder: The sequence number of the node within the execution plan. Kind: The type of operation performed at the node - see the examples below. ResultingDocumentCount: The number of documents returned by this part of the query. Weighting: The weighting score calculated for this part of the query. If the execution of the query didn’t necessitate the score to be calculated, this will be null. DocumentFiltersApplied: The number of document filters applied at this stage. This will be non-null if the results from a preceding evaluation can be used to pre-filter the results at this node, mitigating the need for scoring matches that will just be discarded in a subsequent node. FieldFiltersApplied: The number of field filters applied. Text: A textual representation of the node, providing insight into the specific operation or query part. InclusiveTiming: The total time taken by this node and its children. ExclusiveTiming: The time taken by this node, excluding its children. Children: Child nodes of this node, representing subsequent operations in the query execution process. Node kinds QueryPart Represents a textual query that was evaluated against the index. The text of the node will contain the query.\nUnion Typically introduced by an OR (|) operator. Results from the child nodes are combined into one set. Where documents are present in both nodes, their field matches are combined.\nIntersect Typically introduced by an AND (\u0026) operator. Only document results that are present in both child nodes are returned. Field matches for the intersected documents are combined.\nNote the 3 document filters applied to the second search (SPECIES) - these are the 3 documents that were returned from the first search (ANIMAL). Without those document filters applied, searching for SPECIES would have returned many more documents.\nPositionalIntersect Introduced by the near (~), preceding near (~\u003e) and adjacent words (\"\") operators. Like Intersect, but the locations of the matched tokens are taken into consideration and combined into a composite matched location which allows for the results of multiple positional matches to be combined in sequence. Intersected documents that have no appropriate tokens matching are filtered out.\nPrecedingIntersect Introduced by the preceding (\u003e) operator. Intersects matched documents but only where the matched tokens in the left node precede those in the right node. Intersected documents that have no appropriate tokens matching are filtered out.\nResultsOnly A placeholder node representing the final query results without a specific operation. This will only ever appear if the index was queried without the QueryExecutionOptions.IncludeExecutionPlan option specified.\nUsage Example To analyze a query execution plan, start with the Root node and explore its properties and children. This allows you to trace the execution path, understand the impact of each operation, and identify potential areas for optimization.\nThe Blazor sample provides a way to visualize the query execution plan:\n","categories":"","description":"LIFTI's Query Execution Plan provides detailed insights into the execution of a query, including the order, timing, and the structure of the query parts. \n","excerpt":"LIFTI's Query Execution Plan provides detailed insights into the …","ref":"/lifti/docs/searching/understanding-query-plan/","tags":"","title":"Understanding Query Execution Plans"},{"body":"Every time an index is modified, either with a single document being added or a batch change being completed, a new immutable snapshot is created. This is part of LIFTI’s thread safety mechanism.\nYou can hook into this process by registering an action using the FullTextIndexBuilder\u003cTKey\u003e.WithIndexModificationAction method.\nThis trivial example just logs to the console the number of documents in the index whenever a new snapshot is created.\nvar index = new FullTextIndexBuilder\u003cGuid\u003e() .WithIndexModificationAction(async (idx) =\u003e { Console.WriteLine($\"Index now contains {idx.IdLookup.Count} documents\"); }) .Build(); You can also use this process to automatically serialize the index when modifications occur:\nvar serializer = new BinarySerializer\u003cGuid\u003e(); var index = new FullTextIndexBuilder\u003cGuid\u003e() .WithIndexModificationAction(async (idx) =\u003e { using (var fileStream = await File.OpenWrite(\"myindex.dat\")) { await serializer.SerializeAsync(idx, fileStream); } }) .Build(); ","categories":"","description":"You can register an async action that needs to occur when mutations to the index are committed and a new snapshot is generated.\n","excerpt":"You can register an async action that needs to occur when mutations to …","ref":"/lifti/docs/index-construction/withindexmodificationaction/","tags":"","title":"Adding index modification actions"},{"body":"","categories":"","description":"Low level reference documentation.\n","excerpt":"Low level reference documentation.\n","ref":"/lifti/docs/reference/","tags":"","title":"Reference"},{"body":" This FAQ is a work in progress - as questions are asked, they will be added here for future reference.\nGeneral Is LIFTI thread safe? Yes, this is managed by two mechanisms:\nSingle writer: Locking is enforced so that there can only be one writer at any one time to the index. Snapshots: Whenever changes are committed to the index, a read-only snapshot is taken. Queries are executed against the snapshots, so any modifications that occur during the processing of any given query will not affect them. This means that read operations are lock-free. Serializaton Can I automatically serialize an index when it changes? Yes, you need to add a hook to FullTextIndexBuilder\u003cTKey\u003e.WithIndexModificationAction. There’s an example here.\n","categories":"","description":"Frequently asked questions about LIFTI\n","excerpt":"Frequently asked questions about LIFTI\n","ref":"/lifti/docs/faq/","tags":"","title":"Frequently Asked Questions"},{"body":"LIFTI is a simple to use netstandard2 compatible in-memory full text indexing API.\nIf you are building an application that refers to objects that contain lots of text, and you:\nDon't want to store all the text in memory all the time (e.g. files or other text-based resources)\rWant to be able to search the contents of the text quickly\rThen LIFTI is for you. You could use it in:\nClient applications, e.g. Blazor, UWP, Xamarin, WPF, Uno Platform ASP.NET applications where you need to perform a fast search against a long list of words. An in-memory index of exclusion words could easily be used to do this. Lots of other scenarios! ","categories":"","description":"","excerpt":"LIFTI is a simple to use netstandard2 compatible in-memory full text …","ref":"/lifti/docs/","tags":"","title":"LIFTI"},{"body":"Version 6 (v6.0.0) Notes:\nVersions 2 to 5 are readable as a one-time conversion but always written back as version 6. Int32s are written as positive values using 7-bit encoding. This means that the maximum value is 2,147,483,647, apart from Int32s written by the IntFormatterKeySerializer which can’t make the assumption that the value is always positive. For these, values are written using zig-zag encoding. New in version 6 is the storage of object type and scoring metadata information for a document in the index, including an internal object type id it was extracted for, freshness date and scoring magnitude, if applicable. ","categories":"","description":"The current serialization format is version 6. \n","excerpt":"The current serialization format is version 6. \n","ref":"/lifti/docs/reference/serialization-format/","tags":"","title":"Serialization File Format"},{"body":"Version 5 (v5.0.0) New in version 5 is the list of fields in the index. This is used upon deserialization to rehydrate the dynamic fields and ensure that the field names in the index being deserialized into are mapped correctly to fields in the serialized index. ","categories":"","description":"Documentation for older serialization formats.\n","excerpt":"Documentation for older serialization formats.\n","ref":"/lifti/docs/reference/serialization-format/preversion6/","tags":"","title":"V5 Serialization File Format"},{"body":"Version 4 (v4.0.0) ","categories":"","description":"Documentation for older serialization formats.\n","excerpt":"Documentation for older serialization formats.\n","ref":"/lifti/docs/reference/serialization-format/preversion5/","tags":"","title":"V2-4 Serialization File Format"},{"body":"Given a class called Book:\npublic class Book { public int BookId { get; set; } public string Title { get; set; } public string[] Authors { get; set; } public string Content { get; set; } } Where you want users to be able to search for text in all three Title, Abstract and Content fields, you can build an index as:\n// Books are indexed by their BookId property, which is an int. var bookIndex = new FullTextIndexBuilder\u003cint\u003e() .WithObjectTokenization\u003cBook\u003e( options =\u003e options .WithKey(b =\u003e b.BookId) .WithField(\"Title\", b =\u003e b.Title, tokenOptions =\u003e tokenOptions.WithStemming()) .WithField(\"Authors\", b =\u003e b.Authors) .WithField(\"Synopsis\", b =\u003e b.Synopsis, tokenOptions =\u003e tokenOptions.WithStemming())) .Build(); Indexing a set of books is as easy as:\nbooks = new[] { new Book { BookId = 1, Title = \"The Three Body Problem\", Authors = new[] { \"Liu Cixin\" }, Synopsis = \"The Three-Body Problem (Chinese: 三体; literally: 'Three-Body'; pinyin: sān tǐ) is a hard science fiction novel...\" }, new Book { BookId = 2, Title = \"Dragons of Autumn Twilight\", Authors = new[] { \"Margaret Weis\", \"Tracy Hickman\" }, Synopsis = \"Dragons of Autumn Twilight is a 1984 fantasy novel by American writers Margaret Weis and Tracy Hickman...\" }, } await bookIndex.AddRangeAsync(books); When you get search results back, they will be against the key stored in the index, i.e. the book’s id:\n// Both books contain \"first\" - prints \"Matched documents: 1, 2 with respective scores 0.274884808704732, 0.265418822719626\" var results = bookIndex.Search(\"first\"); Console.WriteLine( \"Matched documents: \" + string.Join(\", \", results.Select(i =\u003e i.Key)) + \" with respective scores: \" + string.Join(\", \", results.Select(i =\u003e i.Score))); // Only first book contains \"the\" in the title - prints \"Matched documents: 1\" results = bookIndex.Search(\"title=the\"); Console.WriteLine(\"Matched documents: \" + string.Join(\", \", results.Select(i =\u003e i.Key))); ","categories":"","description":"You're not restricted to indexing strings against ids - you can also configure an index to extract text out of one or more properties of an object. Each configured property is a *field*.\n","excerpt":"You're not restricted to indexing strings against ids - you can also …","ref":"/lifti/docs/getting-started/indexing-objects/","tags":"","title":"Indexing Objects"},{"body":"Search result order Search results are returned sorted according to the total document score, in descending order. See scoring for more information.\nSearchResult\u0026lt;TKey\u0026gt; TKey Key { get; } The key for the document that matched the search criteria.\nIReadOnlyList\u0026lt;FieldSearchResult\u0026gt; FieldMatches { get; } The fields that were matched for the document. Each of these is scored independently and provides detailed information about the location of the words that were matched.\ndouble Score { get; } The overall score for this match. This is a sum of the scores for this instance’s FieldMatches.\nFieldSearchResult string FoundIn { get; } The name of the field that the search results were found in. This will be one of the field names configured when the index was built, or Unspecified if no fields were configured.\ndouble Score { get; } The score for this particular field.\nIReadOnlyList\u0026lt;TokenLocation\u0026gt; Locations { get; } The TokenLocation instances for the locations of the matched tokens in the field.\n","categories":"","description":"`FullTextIndex\u003cT\u003e.Search` returns `ISearchResults\u003cT\u003e`, which implements `IEnumerable\u003cSearchResult\u003cT\u003e\u003e` and provides other utilities for processing the matched search locations further.","excerpt":"`FullTextIndex\u003cT\u003e.Search` returns `ISearchResults\u003cT\u003e`, which …","ref":"/lifti/docs/searching/search-results/","tags":"","title":"Search Results"},{"body":" About LIFTI The original version of LIFTI was written in 2010 and hosted on CodePlex and evolved to become quite complicated, including automatic persistance to a backing file and support for distributed transactions. Support for netstandard1.3 was added by directly porting it and stripping out incompatible parts, primarily to enable use in a personal UWP project Chordle. This became the beta version of the LIFTI package, and version 1.0.0 of the Lifti.Core package that was largely untouched for years. This new version is a re-write in netstandard2 trying to re-focus on keeping it simple. ","categories":"","description":"","excerpt":" About LIFTI The original version of LIFTI was written in 2010 and …","ref":"/lifti/about/","tags":"","title":"About LIFTI"},{"body":" LIFTI Learn More Source Code Try it out A fast, in-memory, full-text indexer for .NET (netstandard 2.0)\nYou’re just one package away from indexing your text\rInstall-Package Lifti.Core\nRead more …\nContributions welcome!\rWant to help? New users are welcome to get involved in raising issues, but even better getting stuck in with maintaining the code!\nRead more …\nFollow us on Mastodon!\rRead more …\n","categories":"","description":"","excerpt":" LIFTI Learn More Source Code Try it out A fast, in-memory, full-text …","ref":"/lifti/","tags":"","title":"LIFTI - A Lightweight Full Text Indexing library for .NET"},{"body":"","categories":"","description":"","excerpt":"","ref":"/lifti/search/","tags":"","title":"Search Results"}]